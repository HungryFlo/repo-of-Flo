# d2l笔记：7 现代卷积神经网络

## 7.1 深度卷积神经网络(AlexNet)

### 网络结构（简化版）

<img src="F:\repo-of-Flo\ml-learning\d2l-notes\d2l笔记：7 现代卷积神经网络.assets\image-20240305112951727.png" alt="image-20240305112951727" style="zoom:50%;" />

八层：五个卷积层（1+1+3）和三个全连接层（两个全连接隐藏层和一个全连接输出层）

使用ReLU作为激活函数。

通过暂退法控制全连接层的模型复杂度。

还是用了数据扩增技术来增加了大量的图像增强数据，使得模型更加健壮，也有效减少了过拟合。

## 7.2 使用块的网络

### VGG块

经典卷积神经网络的基本组成部分是下面的这个序列：

1. 带填充以保持分辨率的卷积层；
2. 非线性激活函数，如ReLU；
3. 汇聚层，如最大汇聚层。

## 7.3 网络中的网络（NiN）

前面的 LeNet, AlexNet, VGG 都是通过一系列卷积层与汇聚层来提取空间结构特征，然后通过全连接层对特征的表征进行处理。如果想要在这个过程的早期使用全连接层，好像又放弃了表征的空间结构。

网络中的网络提供了一个非常简单的解决方案：在每个像素的通道上分别使用多层感知机。

